---
title: "US Border Entry"
author: "Varun Vasudeva"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(gridExtra)
library(tidyverse)
library(knitr)
library(ggfortify)
library(lindia)
library(leaps)
library(car)
library(GGally)
library(caret)
library(dplyr)
```

This report aims to build a simple predictive model for the number of entrants in a month given a year between 1996 and 2020, a port of entry, and a mode of transportation. In it, we will explore the data and draw inferences about trends, build successive linear regression models using multiple predictors, and eventually validate the model to determine the true error of prediction.

After loading the necessary libraries for analysis, we can read the data from the comma-separated-value (CSV) file and view the first 6 entries. The data was sourced from https://www.kaggle.com/divyansh22/us-border-crossing-data and is a dataset involving the US Border and crossing data related to it.

```{r}
border <- read.csv("Border_Crossing_Entry_Data.csv")
head(border)
```

Next, we need to reconstruct the data in order to assist with meaningful exploratory data analysis (or EDA) so we can glean relevant information from the graphs. We've extracted the year from the Date column and allotted it to a separate column called `Year`. 

We've also split the data into five sections: 1996 - 2000, 2001 - 2005, 2006 - 2010, 2011 - 2015, and 2016 - 2020. This will help us analyze what happens to immigration into the United States over these five periods, so we can gather a general trend.

```{r data reconstruction}
border <- border %>%
  mutate(Year = format(as.Date(border$Date, format="%d/%m/%Y"),"%Y"),
         ModYear = case_when(Year >= 1996 & Year <= 2000 ~ "1996 - 2000",
                            Year >= 2001 & Year <= 2005 ~ "2001 - 2005",
                            Year >= 2006 & Year <= 2010 ~ "2006 - 2010",
                            Year >= 2011 & Year <= 2015 ~ "2011 - 2015",
                            Year >= 2016 & Year <= 2020 ~ "2016 - 2020")) %>%
  filter(!Value %in% c(0)) %>%
  drop_na()
head(border)
```

We've reconstructed the data in order to exclude Value entries that are equal to 0, for purposes that will be discussed later on.

We can utilize a bar graph facet-wrapped by `ModYear` to observe a trend in immigration patterns over the five splits from 1996 - 2020.

```{r ModYear EDA, cache = TRUE}
ggplot(border, aes(x = State, y = Value, col = State)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ModYear) +
  theme(axis.text.x = element_text(angle = 60))
```

We see clearly that Texas has the greatest immigration influx out of all states that contribute to the influx of immigrants. California stands second in terms of number of immigrants coming into the United States, and Arizona stands third. 

This indicates that the US-Mexico border is far busier than the US-Canada border, which is a known fact. However, we see something more interesting at play: immigration through Texas has been in decline over the years, with the 2016-2020 season seeing the lowest number of incoming immigrants from the other seasons begininng 1996, a decrease of 50 million the 1996 - 2000 season. California and Arizona, on the other hand, have remained largely consistent as far as the number of immigrants per season.

```{r Border EDA, cache = TRUE}
ggplot(border, aes(x = State, y = Value, col = State)) +
  geom_bar(stat = "identity") +
  facet_wrap(~Border) +
  theme(axis.text.x = element_text(angle = 45))
```

Upon facet-wrapping the same data by `Border`, we can effectively compare the two borders in terms of their total immigration from 1996 - 2020. We can see that Texas has nearly quadrupled the number of incoming immigrants from the likes of New York and Michigan, and is around 33% more than California.

New Mexico is the lowest contributor to the US-Mexico border and Ohio seems to be the lowest contributor to the US-Canada border.

Next, we'll create a full linear regression model both so we can see how it performs and for the purpose of eliminating unnecessary variables using the `step()` function, which will perform a stepwise elimination of irrelevant variables. These following models are aimed at predicting the number of incoming migrants from a particular port of entry in an arbitrary month in a given year.

```{r full model, cache = TRUE}
border.full <- lm(Value ~ Port.Name + State + Port.Code + Border + Measure + Year, data = border)
summary(border.full)
```

Upon analyzing this model, we can see that it can definitely significantly (p-value < 2.2e-16) predict the number of immigrants given the relevant information it needs. The model has an F-statistic = 969.4 on 151 and 232967 df with RSE = 145700 on 232967 df. We see a lot of NA values for the `State` variable so we'll create another model omitting it.

```{r reduced model, cache = TRUE}
border.reduced <- lm(Value ~ Port.Name + Port.Code + Border + Measure + Year, data = border)
summary(border.reduced)
```

However, we want to see whether the model can be improved (or even kept largely the same) without the presence of as many variables. Now, we create the backward stepwise model.

```{r backward stepwise, cache = TRUE}
border.backward <- step(border.reduced, direction = "backward")
```

This process removed the variable `Border`. It is understandable that `Border` does not need to be present in the model as `Border` simply reaffirms what `Port.Name` already tells us. It also makes sense that we need the year along with what measure of travel we're trying to predict the influx of immigrants for.

```{r backward stepwise, continued, cache = TRUE}
summary(border.backward)
autoplot(border.backward)
```

This backwards stepwise model has an F-statistic = 969.4 on 151 and 232967 df with RSE = 145700 on 232967 df. The p-value, Adjusted R-squared, and RSE are the same as the reduced model, but the model is simpler and requires less data for predictive purposes, so this is the one we keep and carry on with.

However, we see major issues with normality and the Residuals vs. Leverage plot having an extremely high y-axis range. We can run a Box-Cox test in order to determine how to fix these issues. This is why we reconstructed the data to remove all Value entries that were 0. In case a log transformation is necessary, data points with a Value = 0 would throw off the test and make it impossible to diagnose the rest of the data points.

```{r box-cox, cache = TRUE}
gg_boxcox(border.backward)
```

As we can see from the output above, the ideal $\lambda$ value = 0, meaning a log transformation would suffice in attempting to fix issues as shown by the `autoplot()` function. We now create a new model called `border.fit` in order to improve on the backward stepwise model. In this mode, however, we will omit `Port.Code` simply because having the value for `Port.Name` gives us the value for `Port.Code` already.

```{r border.fit, cache = TRUE}
border.fit <- lm(log(Value) ~ Port.Name + Measure + Year, data = border)
summary(border.fit)
autoplot(border.fit)
```

This model is easily the best one yet and we can see that log-transforming the response variable fixed the multitude of issues we saw in the dataset. The normality, as seen in the Normal QQ Plot is, has been largely fixed, as the line is approximately diagonal. Compared to a y-axis range in the hundreds of thousands, the y-axis range in the Residuals vs. Leverage plot is now -10 to 5. Also in the Residuals vs Leverage plot, the line is almost completely horizontal, alluding to a largely constant variance. The model sees a dramatic increase in the F-statistic, which now stands at 6139 on 150 and 232968 df with an unbelievably low RSE of 1.387 on 232968 df. The Adjusted R-squared value is a healthy 79.8%, meaning most of the variance in the data is explained by the model. As always, the model's p-value still remains significant, meaning the model can predict the response variable with some significance.

Next, we run a 5-fold cross validation in order to create a slightly more realistic model that doesn't predict the same data it's trained with.

```{r 5-fold CV, cache = TRUE}
set.seed(536255)
train_control <- trainControl(method = "cv", number = 5)
border.cv <- train(log(Value) ~ Port.Name + Measure + Year, data = border, trControl = train_control, method="lm")
print(border.cv)
```

The RMSE is 1.387064, which is the same as the RSE of 1.387 on the previous model. This model is the most accurate one so far, by virtue of it iteratively predicting different data that what the model was trained on. Thus, we can go ahead and make a prediction using the `border.cv` model.

```{r prediction, cache = TRUE}
new_data = data.frame(Port.Name = "Santa Teresa", Measure = "Buses", Year = "2010")
exp(predict(border.cv, newdata = new_data))

test.df <- data.frame(filter(border, Port.Name == "Santa Teresa" & Measure == "Buses" & Year == "2010"))
mean(test.df$Value)
```

This sample prediction states that in a month in 2010, from the port of Santa Teresa, NM, 37 people will enter the United States via the Buses Measure. Comparing it to the average of the months in 2010 with the same criterion applied, we see that the model over-predicts by a very small margin. However, it gives an accurate estimate of how many people can be expected in a given month. Also, considering the RMSE of the model is 1.387 with 233119 samples, the model is fairly accurate.

Over the last two seasons (2011 - 2015 and 2016 - 2020), the data has remained fairly consistent, as seen in our EDA. Thus, this model can be used to predict future data from past data.
